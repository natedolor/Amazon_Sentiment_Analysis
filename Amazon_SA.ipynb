{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Amazon Product for Sentiment Analysis\n",
    "\n",
    "\n",
    "For this project, I will be web scraping an Amazon product for the usage of sentiment analysis. The data will be scraped and made into a dataset that will be primarily comprised of the User's profile name, the reviewer star rating, the review, and the review of the summary. Using the VADER and Roberta model, I should be able to analyze the sentiment of User's review and compare the reviewer star rating and the sentiment of the review.\n",
    "\n",
    "\n",
    "For this project, I will primarily focus on one product, [COSRX Snail Mucin](https://www.amazon.com/COSRX-Repairing-Hydrating-Secretion-Phthalates/dp/B00PBX3L7K/ref=cm_cr_arp_d_product_top?ie=UTF8), for which I will do web scraping and sentiment anaylsis on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extract data\n",
    "\n",
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find('span', attrs = {'class':'a-size-large product-title-word-break'})\n",
    "\n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.txt\n",
    "\n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Profile Name\n",
    "def get_profile_name(soup):\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        profile = soup.find('span', attrs = {'class':'a-profile-name'})\n",
    "\n",
    "        # Inner NavigatableString Object\n",
    "        profile_value = profile.string()\n",
    "\n",
    "        # Profile as a string value\n",
    "        profile_string = profile_value.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        profile_string = \"\"\n",
    "\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Reviewer Star Rating\n",
    "\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find('i', attrs = {'data-hook':'review-star-rating'})\n",
    "\n",
    "    except AttributeError:\n",
    "        rating = ''\n",
    "\n",
    "# Function to extract Review\n",
    "\n",
    "def get_review(soup):\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        review = soup.find('span', attrs = {'class':'a-size-base review-text review-text-content'})\n",
    "\n",
    "        # Inner NavigatableString Object\n",
    "        review_value = review.string()\n",
    "\n",
    "        # Profile as a string value\n",
    "        review_string = review_value.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        review_string = \"\"\n",
    "\n",
    "    return review_string\n",
    "\n",
    "# Function to extract Review Summary\n",
    "\n",
    "def get_review_summary(soup):\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        summary = soup.find('span', attrs = {'class':'a-letter-space'})\n",
    "\n",
    "        # Inner NavigatableString Object\n",
    "        summary_value = summary.string()\n",
    "\n",
    "        # Profile as a string value\n",
    "        summary_string = summary.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        summary_string = \"\"\n",
    "\n",
    "    return summary_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data\n",
    "\n",
    "Data will be extracted here in a clean way by going through each page of the reviews and putting them into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__name__ == '__main__'\n",
    "\n",
    "# User Agent\n",
    "\n",
    "HEADERS = ({'User-Agent': '', 'Accept-Lanugage': 'en-US, en;q=0.5'})\n",
    "\n",
    "# Webpage URL\n",
    "\n",
    "URL = \"https://www.amazon.com/COSRX-Repairing-Hydrating-Secretion-Phthalates/dp/B00PBX3L7K/ref=cm_cr_arp_d_product_top?ie=UTF8\"\n",
    "REVIEWS_URL = \"https://www.amazon.com/COSRX-Repairing-Hydrating-Secretion-Phthalates/product-reviews/B00PBX3L7K/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=1\"\n",
    "\n",
    "# HTTP Request\n",
    "\n",
    " webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "# Soup Object containing all data\n",
    "\n",
    "soup = BeautifulSoup(webpage.content, \"html.parser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
