{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Amazon Product for Sentiment Analysis\n",
    "\n",
    "\n",
    "For this project, I will be web scraping an Amazon product for the usage of sentiment analysis. The data will be scraped and made into a dataset that will be primarily comprised of the User's profile name, the reviewer star rating, the review, and the review of the summary. Using the VADER and Roberta model, I should be able to analyze the sentiment of User's review and compare the reviewer star rating and the sentiment of the review.\n",
    "\n",
    "\n",
    "For this project, I will primarily focus on one product, [COSRX Snail Mucin](https://www.amazon.com/COSRX-Repairing-Hydrating-Secretion-Phthalates/dp/B00PBX3L7K/ref=cm_cr_arp_d_product_top?ie=UTF8), for which I will do web scraping and sentiment anaylsis on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests_html in /home/ndolor/.local/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: fake-useragent in /home/ndolor/.local/lib/python3.10/site-packages (from requests_html) (1.2.1)\n",
      "Requirement already satisfied: bs4 in /home/ndolor/.local/lib/python3.10/site-packages (from requests_html) (0.0.1)\n",
      "Requirement already satisfied: pyquery in /home/ndolor/.local/lib/python3.10/site-packages (from requests_html) (2.0.0)\n",
      "Requirement already satisfied: w3lib in /home/ndolor/.local/lib/python3.10/site-packages (from requests_html) (2.1.2)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in /home/ndolor/.local/lib/python3.10/site-packages (from requests_html) (1.0.2)\n",
      "Requirement already satisfied: parse in /home/ndolor/.local/lib/python3.10/site-packages (from requests_html) (1.19.1)\n",
      "Requirement already satisfied: requests in /home/ndolor/.local/lib/python3.10/site-packages (from requests_html) (2.31.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /home/ndolor/.local/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/lib/python3/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.6.4)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /home/ndolor/.local/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests_html) (1.26.16)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in /home/ndolor/.local/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests_html) (10.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /home/ndolor/.local/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests_html) (4.66.1)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /home/ndolor/.local/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests_html) (8.2.2)\n",
      "Requirement already satisfied: certifi>=2021 in /home/ndolor/.local/lib/python3.10/site-packages (from pyppeteer>=0.0.14->requests_html) (2023.7.22)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ndolor/.local/lib/python3.10/site-packages (from bs4->requests_html) (4.12.2)\n",
      "Requirement already satisfied: lxml>=2.1 in /home/ndolor/.local/lib/python3.10/site-packages (from pyquery->requests_html) (4.9.3)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in /home/ndolor/.local/lib/python3.10/site-packages (from pyquery->requests_html) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ndolor/.local/lib/python3.10/site-packages (from requests->requests_html) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ndolor/.local/lib/python3.10/site-packages (from requests->requests_html) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ndolor/.local/lib/python3.10/site-packages (from beautifulsoup4->bs4->requests_html) (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data\n",
    "\n",
    "Data will be extracted here in a clean way by going through each page of the reviews and putting them into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseParser.find() got an unexpected keyword argument 'attrs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     42\u001b[0m     amz \u001b[39m=\u001b[39m Extract(\u001b[39m'\u001b[39m\u001b[39mB00PBX3L7K\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     reviews \u001b[39m=\u001b[39m amz\u001b[39m.\u001b[39;49mpagination(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     44\u001b[0m     \u001b[39mprint\u001b[39m(amz\u001b[39m.\u001b[39mparse(reviews))\n",
      "Cell \u001b[0;32mIn[74], line 16\u001b[0m, in \u001b[0;36mExtract.pagination\u001b[0;34m(self, page)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpagination\u001b[39m(\u001b[39mself\u001b[39m, page):\n\u001b[1;32m     15\u001b[0m     webpage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreviews_url \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(page))\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m webpage\u001b[39m.\u001b[39;49mhtml\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m'\u001b[39;49m, attrs \u001b[39m=\u001b[39;49m {\u001b[39m'\u001b[39;49m\u001b[39mdata-hook\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mreview\u001b[39;49m\u001b[39m'\u001b[39;49m}):\n\u001b[1;32m     17\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseParser.find() got an unexpected keyword argument 'attrs'"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "class Extract:\n",
    "    def __init__(self, asin) -> None:\n",
    "        self.asin = asin\n",
    "        # User Agent\n",
    "        self.headers = ({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36', 'Accept-Lanugage': 'en-US, en;q=0.5'})\n",
    "        # Webpage URL\n",
    "        self.url = \"https://www.amazon.com/COSRX-Repairing-Hydrating-Secretion-Phthalates/dp/B00PBX3L7K/ref=cm_cr_arp_d_product_top?ie=UTF8\"\n",
    "        self.reviews_url = f'https://www.amazon.com/product-reviews/{self.asin}/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber='\n",
    "        self.webpage = requests.get(self.reviews_url, headers = self.headers)\n",
    "        self.session = HTMLSession() #BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    def pagination(self, page):\n",
    "        webpage = self.session.get(self.reviews_url + str(page))\n",
    "        if not webpage.html.find('div[data-hook=review]'):\n",
    "            return False\n",
    "        else:\n",
    "            return webpage.html.find('div[data-hook=review]')\n",
    "\n",
    "    # Functions to extract data\n",
    "\n",
    "# Function to extract Product Title\n",
    "    def get_product(soup):\n",
    "        try:\n",
    "            # Outer Tag Object\n",
    "            product = webpage.html.find('span[class=a-size-large product-title-word-break]')\n",
    "\n",
    "            # Inner NavigatableString Object\n",
    "            product_value = product.txt\n",
    "\n",
    "            # Title as a string value\n",
    "            product_string = product.strip()\n",
    "\n",
    "        except AttributeError:\n",
    "            product_string = \"\"\n",
    "\n",
    "        return product_string\n",
    "\n",
    "# Function to extract Profile Name\n",
    "    def get_profile_name(soup):\n",
    "        try:\n",
    "            # Outer Tag Object\n",
    "            profile = webpage.html.find('span[class':'a-profile-name]')\n",
    "\n",
    "            # Profile as a string value\n",
    "            profile_string = profile.text\n",
    "\n",
    "        except AttributeError:\n",
    "            profile_string = \"\"\n",
    "\n",
    "        return profile_string\n",
    "\n",
    "# Function to extract Reviewer Star Rating\n",
    "\n",
    "    def get_rating(soup):\n",
    "        try:\n",
    "            rating = soup.find('i', attrs = {'data-hook':'review-star-rating'}).text\n",
    "\n",
    "        except AttributeError:\n",
    "            rating = ''\n",
    "        \n",
    "        return rating\n",
    "\n",
    "# Function to extract Review\n",
    "\n",
    "    def get_review(soup):\n",
    "        try:\n",
    "            # Outer Tag Object\n",
    "            review = webpage.html.find('i', attrs = {'data-hook':'a-size-base review-text review-text-content'})\n",
    "\n",
    "            # Profile as a string value\n",
    "            review_string = review.text\n",
    "\n",
    "        except AttributeError:\n",
    "            review_string = \"\"\n",
    "\n",
    "        return review_string[0:25]\n",
    "\n",
    "# Function to extract Review Summary\n",
    "\n",
    "    def get_review_summary(soup):\n",
    "        try:\n",
    "            # Outer Tag Object  #FIX\n",
    "            summary = soup.find('span', attrs = {'class':'a-letter-space'})\n",
    "\n",
    "            # Profile as a string value\n",
    "            summary_string = summary.text\n",
    "\n",
    "        except AttributeError:\n",
    "            summary_string = \"\"\n",
    "\n",
    "        return summary_string\n",
    "        \n",
    "    def parse(self, reviews):\n",
    "        all_reviews = []\n",
    "        for review in reviews:\n",
    "            title_page = get_product(soup)\n",
    "            profile_name = get_profile_name(soup)\n",
    "            rating = get_rating(soup)\n",
    "            review_string = get_review(soup)\n",
    "            review_summary = get_review_summary(soup)\n",
    "\n",
    "            data = {\n",
    "                'title' : title_page,\n",
    "                'profile' : profile_name,\n",
    "                'rating' : rating,\n",
    "                'review' : review_string,\n",
    "                'review_summary' : review_summary\n",
    "            }\n",
    "            all_reviews.append(data)\n",
    "        return all_reviews\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    amz = Extract('B00PBX3L7K')\n",
    "    reviews = amz.pagination(1)\n",
    "    print(amz.parse(reviews))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
